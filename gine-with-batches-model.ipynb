{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4217d32e-7cd9-4183-8575-07abf0a27d3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6ee9e0-46e5-4d17-a141-ece1bc3ff376",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run this cell if on mac\n",
    "\n",
    "import torch\n",
    "\n",
    "# mps runs out of memory without batches, and neighbor batches aren't supported on mac yet\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b66960f-8982-4152-8aca-a38a4ac8195b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# get data (need git LFS)\n",
    "node_path = Path(\"dataset\") / \"HI-Small_accounts.csv\"\n",
    "edge_path = Path(\"dataset\") / \"HI-Small_Trans.csv\"\n",
    "node_data = pd.read_csv(node_path)\n",
    "edge_data = pd.read_csv(edge_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ac29c1-6c9f-4c08-a714-4457622c2abb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# use indices from accounts dataset for node indices\n",
    "accounts = node_data.reset_index()[['Account Number', 'index']]\n",
    "num_nodes = accounts.shape[0]\n",
    "compact = {accounts['Account Number'][i]: accounts['index'][i] for i in range(num_nodes)}\n",
    "to_node = np.vectorize(lambda x: compact[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50558c81-4530-42a1-94e5-dd7b80c4c494",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "# create adjacency list in COO format\n",
    "source = to_node(edge_data['Account'])\n",
    "target = to_node(edge_data['Account.1'])\n",
    "edge_index = torch.from_numpy(np.vstack([source, target])).to(device)\n",
    "\n",
    "num_edges = edge_index.shape[1]\n",
    "\n",
    "g = Data(edge_index=edge_index, num_nodes=num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c9d5c0-bbae-4718-bdb6-35bea16cf0a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.utils import degree\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# create bank frequency column\n",
    "freq = node_data['Bank ID'].value_counts()\n",
    "id_freq = np.vectorize(lambda x: freq[x])\n",
    "node_data['Bank Frequency'] = id_freq(node_data['Bank ID'])\n",
    "node_data['Bank Frequency'] = pd.cut(node_data['Bank Frequency'], bins=[0, 2, 10, 100, 4000], labels=[0, 1, 2, 3])\n",
    "\n",
    "# use one hot encoding for categorical variables\n",
    "bank_enc = OneHotEncoder(sparse_output=False)\n",
    "bank_frequency = bank_enc.fit_transform(node_data['Bank Frequency'].to_numpy().reshape(-1, 1))\n",
    "\n",
    "paid_enc = OneHotEncoder(sparse_output=False)\n",
    "currency_sent = paid_enc.fit_transform(edge_data['Payment Currency'].to_numpy().reshape(-1, 1))\n",
    "\n",
    "received_enc = OneHotEncoder(sparse_output=False)\n",
    "currency_received = received_enc.fit_transform(edge_data['Receiving Currency'].to_numpy().reshape(-1, 1))\n",
    "\n",
    "format_enc = OneHotEncoder(sparse_output=False)\n",
    "pay_format = format_enc.fit_transform(edge_data['Payment Format'].to_numpy().reshape(-1, 1))\n",
    "\n",
    "# create numerical variables\n",
    "time_trans = pd.to_datetime(edge_data['Timestamp']).astype('int64') / 1e9\n",
    "amount_sent = edge_data['Amount Paid'].to_numpy()\n",
    "amount_received = edge_data['Amount Received'].to_numpy()\n",
    "\n",
    "# combine all edge features into one tensor with dtype = float32\n",
    "edge_features = torch.from_numpy(np.column_stack([time_trans, amount_received,\n",
    "                                                  currency_received, pay_format])).float().to(device)\n",
    "edge_dim = edge_features.shape[1]\n",
    "\n",
    "# edge label with 0 = not laundering, 1 = is laundering\n",
    "label = torch.from_numpy(edge_data['Is Laundering'].to_numpy()).long().to(device)\n",
    "\n",
    "g.x = torch.from_numpy(bank_frequency).float().to(device)\n",
    "g.edge_attr = F.normalize(edge_features)\n",
    "g.edge_label = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721ece0e-3927-4602-a1ff-6765ce7a88d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# chronological 60/20/20 split\n",
    "\n",
    "train_end = int(0.6 * num_edges)\n",
    "val_end = int(0.8 * num_edges)\n",
    "\n",
    "train_idx = torch.zeros(num_edges, dtype=torch.bool)\n",
    "train_idx[:train_end] = True\n",
    "\n",
    "val_idx = torch.zeros(num_edges, dtype=torch.bool)\n",
    "val_idx[train_end:val_end] = True\n",
    "\n",
    "test_idx = torch.zeros(num_edges, dtype=torch.bool)\n",
    "test_idx[val_end:] = True\n",
    "\n",
    "#g.train_mask = train_idx\n",
    "#g.val_mask = val_idx\n",
    "#g.test_mask = test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab993a4f-25c1-4846-a7d8-14f1741ac5bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "pos_weight = 10\n",
    "\n",
    "embedding_dim = 64\n",
    "\n",
    "hidden = 64\n",
    "\n",
    "learn_rate = 0.005\n",
    "\n",
    "dropout = 0.5\n",
    "\n",
    "num_neighbors = [20, 10]\n",
    "\n",
    "batch_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061f4f28-349d-4507-870a-bd88445bfbbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GINEConv\n",
    "import torch.nn as nn\n",
    "\n",
    "# node embedding model\n",
    "class GNN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, embedding_dim, edge_feat_dim, dropout):\n",
    "        super().__init__()        \n",
    "        self.in_channels = in_channels\n",
    "        self.hidden = hidden_channels\n",
    "        self.dim = embedding_dim\n",
    "        self.edge_dim = edge_feat_dim\n",
    "        self.drop = dropout\n",
    "        \n",
    "        # linear embeddings\n",
    "        self.node_embedding = nn.Linear(self.in_channels, self.dim)\n",
    "        self.edge_embedding = nn.Linear(self.edge_dim, self.dim)\n",
    "        \n",
    "        # convolution layers for node embedding\n",
    "        self.conv1 = GINEConv(nn.Sequential(\n",
    "                    nn.Linear(self.dim, self.dim),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(self.dim, self.dim)\n",
    "                    ), edge_dim=self.dim)\n",
    "        self.conv2 = GINEConv(nn.Sequential(\n",
    "                    nn.Linear(self.dim, self.dim),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(self.dim, self.dim)\n",
    "                    ), edge_dim=self.dim)\n",
    "        \n",
    "        # mlp for edge embedding\n",
    "        self.mlp_edge = nn.Sequential(\n",
    "            nn.Linear(self.dim*3, self.dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.dim, self.dim),\n",
    "        )\n",
    "        \n",
    "        # mlp for edge classifier\n",
    "        self.mlp_classifier = nn.Sequential(\n",
    "            nn.Linear(self.dim*3, self.hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(self.drop),\n",
    "            nn.Linear(self.hidden, self.hidden // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(self.drop),\n",
    "            nn.Linear(self.hidden // 2, 2)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        u, v = edge_index\n",
    "        edge_pairs = torch.transpose(edge_index, 0, 1)\n",
    "        x = self.node_embedding(x)\n",
    "        edge_attr = self.edge_embedding(edge_attr)\n",
    "        \n",
    "        # message passing with averaging aggregation method\n",
    "        x = 0.5 * (x + F.relu(self.conv1(x, edge_index, edge_attr)))\n",
    "        edge_attr = edge_attr + 0.5*self.mlp_edge(torch.cat([x[u], x[v], edge_attr], dim=-1))\n",
    "        \n",
    "        x = 0.5 * (x + F.relu(self.conv2(x, edge_index, edge_attr)))\n",
    "        edge_attr = edge_attr + 0.5*self.mlp_edge(torch.cat([x[u], x[v], edge_attr], dim=-1))\n",
    "        \n",
    "        # combine embedding of source, target, and edge features\n",
    "        x = x[edge_pairs].reshape(-1, 2*self.dim).relu()\n",
    "        return self.mlp_classifier(torch.cat([x, edge_attr], dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83426b9-b278-40da-8867-be1c46ad7804",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, precision_recall_curve, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# evaluate performance\n",
    "def evaluate(split_idx):\n",
    "    gnn.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = gnn(g.x, g.edge_index, g.edge_attr)\n",
    "        y = g.edge_label[split_idx]\n",
    "        preds = logits[split_idx].argmax(dim=-1)\n",
    "        accuracy = accuracy_score(y, preds)\n",
    "        precision = precision_score(y, preds, zero_division=0.0)\n",
    "        recall = recall_score(y, preds, zero_division=0.0)\n",
    "        f1 = f1_score(y, preds, zero_division=0.0)\n",
    "        return [accuracy, precision, recall, f1]\n",
    "\n",
    "def plots(split_idx):\n",
    "    gnn.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = gnn(g.x, g.edge_index, g.edge_attr)\n",
    "        y = g.edge_label[split_idx]\n",
    "        preds = logits[split_idx].argmax(dim=-1)\n",
    "        cm = confusion_matrix(y, preds)\n",
    "        \n",
    "        # plot confusion matrix for default threshold\n",
    "        plt.figure(1)\n",
    "        ConfusionMatrixDisplay(cm).plot() \n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.show()\n",
    "        \n",
    "        # plot loss curve\n",
    "        plt.figure(2)\n",
    "        plt.plot(loss_values)\n",
    "        plt.xticks(range(0,epochs))\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Validation Loss')\n",
    "        plt.show()\n",
    "        \n",
    "        # plot precision-recall curve \n",
    "        plt.figure(3)\n",
    "        precision, recall, thresholds = precision_recall_curve(y, logits[:, 1])\n",
    "        plt.plot(recall, precision, label=f'Precision-Recall Curve')\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.title('Precision-Recall Curve')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230b9af0-747b-4030-b25b-6a35a9bf8324",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "\n",
    "train_loader = LinkNeighborLoader(g, num_neighbors=num_neighbors,\n",
    "                                  edge_label_index=edge_index[:, train_idx],\n",
    "                                  edge_label=train_idx,\n",
    "                                  shuffle=True)\n",
    "\n",
    "val_loader = LinkNeighborLoader(g, num_neighbors=num_neighbors,\n",
    "                                edge_label_index=edge_index[:, train_idx],\n",
    "                                edge_label=train_idx,\n",
    "                                shuffle=True)\n",
    "\n",
    "test_loader = LinkNeighborLoader(g, num_neighbors=num_neighbors,\n",
    "                                 edge_label_index=edge_index[:, train_idx],\n",
    "                                 edge_label=train_idx,\n",
    "                                 shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25290c5e-4ab8-4061-a3fc-06d4a38be909",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# instantiate model\n",
    "gnn = GNN(4, hidden, embedding_dim, edge_dim, dropout).to(device)\n",
    "weight = torch.tensor([1, pos_weight]).float().to(device)\n",
    "optimizer = optim.Adam(gnn.parameters(), lr=learn_rate)\n",
    "criterion = nn.CrossEntropyLoss(weight=weight).to(device)\n",
    "        \n",
    "# training loop\n",
    "loss_values = []\n",
    "for epoch in range(epochs):\n",
    "    for batch in train_loader:\n",
    "        gnn.train()\n",
    "        optimizer.zero_grad()\n",
    "        logits = gnn(batch.x, batch.edge_index, batch.edge_attr)\n",
    "        loss = criterion(logits[train_idx], g.edge_label[train_idx])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    loss_values.append(loss.item())\n",
    "    val_metrics = evaluate(val_idx)\n",
    "    print(f'Epoch {epoch+1:02d} | loss {loss.item():.4f} | accuracy {val_metrics[0]:.4f} | precision {val_metrics[1]:.4f}| recall {val_metrics[2]:.4f}| f1 {val_metrics[3]:.4f}')\n",
    "\n",
    "# evaluate metrics on test data\n",
    "test_metrics = evaluate(test_idx)\n",
    "print('\\n')\n",
    "print(f'Test Accuracy: {test_metrics[0]:.4f}')\n",
    "print(f'Test Precision: {test_metrics[1]:.4f}')\n",
    "print(f'Test Recall: {test_metrics[2]:.4f}')\n",
    "print(f'Test f1: {test_metrics[3]:.4f}')\n",
    "\n",
    "\n",
    "plots(test_idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

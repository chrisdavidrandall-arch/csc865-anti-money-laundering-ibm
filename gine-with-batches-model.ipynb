{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip uninstall torch torch-scatter torch-sparse torch-geometric torch-cluster torchvision --y\n",
        "!pip install torch==2.2.0 torchvision==0.17.0 --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "import torch\n",
        "TORCH_VERSION = \"2.2.0\"\n",
        "CUDA_VERSION = \"118\"\n",
        "\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-{TORCH_VERSION}+cu{CUDA_VERSION}.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-{TORCH_VERSION}+cu{CUDA_VERSION}.html\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-{TORCH_VERSION}+cu{CUDA_VERSION}.html\n",
        "!pip install pyg-lib -f https://data.pyg.org/whl/torch-{TORCH_VERSION}+cu{CUDA_VERSION}.html\n",
        "!pip install torch-geometric==2.5.0 -f https://data.pyg.org/whl/torch-{TORCH_VERSION}+cu{CUDA_VERSION}.html\n",
        "\n",
        "!pip uninstall numpy --yes\n",
        "!pip install numpy==1.26.4"
      ],
      "metadata": {
        "id": "5jE30vjObGjB"
      },
      "id": "5jE30vjObGjB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "998b04ed",
        "outputId": "cf4896e2-c3fa-40b3-a927-972ad6861ab7"
      },
      "source": [
        "import os\n",
        "!pip install kaggle\n",
        "os.makedirs('/root/.kaggle', exist_ok=True)"
      ],
      "id": "998b04ed",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.11.12)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "new_cell_1",
        "outputId": "cc7e8842-feb1-4603-a100-4aeb45155716"
      },
      "source": [
        "import json\n",
        "\n",
        "kaggle_credentials = {\"username\":\"qmulberry\",\"key\":\"KGAT_0b8dba1122eb1899edcec446e08f9011\"}\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as f:\n",
        "    json.dump(kaggle_credentials, f)\n",
        "\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "\n",
        "print(\"Kaggle API key configured successfully!\")"
      ],
      "id": "new_cell_1",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kaggle API key configured successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "new_cell_2",
        "outputId": "40b30584-87f2-4c99-f042-d4c4bebc7c97"
      },
      "source": [
        "# Create the dataset directory if it doesn't exist\n",
        "import os\n",
        "os.makedirs('dataset', exist_ok=True)\n",
        "\n",
        "# Download and unzip the dataset into the 'dataset' directory\n",
        "!kaggle datasets download -d ealtman2019/ibm-transactions-for-anti-money-laundering-aml -p dataset --unzip\n",
        "\n",
        "print(\"Dataset downloaded and unzipped successfully into 'dataset' directory!\")"
      ],
      "id": "new_cell_2",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/ealtman2019/ibm-transactions-for-anti-money-laundering-aml\n",
            "License(s): Community Data License Agreement - Sharing - Version 1.0\n",
            "Downloading ibm-transactions-for-anti-money-laundering-aml.zip to dataset\n",
            " 99% 7.54G/7.61G [00:18<00:00, 476MB/s]\n",
            "100% 7.61G/7.61G [00:18<00:00, 439MB/s]\n",
            "Dataset downloaded and unzipped successfully into 'dataset' directory!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4217d32e-7cd9-4183-8575-07abf0a27d3c",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4217d32e-7cd9-4183-8575-07abf0a27d3c",
        "outputId": "747aea8a-b0d2-4ca7-8a83-ca173d828d6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = torch.device('mps')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "1b66960f-8982-4152-8aca-a38a4ac8195b",
      "metadata": {
        "tags": [],
        "id": "1b66960f-8982-4152-8aca-a38a4ac8195b"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# get data (need git LFS)\n",
        "node_path = Path(\"dataset\") / \"HI-Small_accounts.csv\"\n",
        "edge_path = Path(\"dataset\") / \"HI-Small_Trans.csv\"\n",
        "node_data = pd.read_csv(node_path)\n",
        "edge_data = pd.read_csv(edge_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d4ac29c1-6c9f-4c08-a714-4457622c2abb",
      "metadata": {
        "tags": [],
        "id": "d4ac29c1-6c9f-4c08-a714-4457622c2abb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# use indices from accounts dataset for node indices\n",
        "accounts = node_data.reset_index()[['Account Number', 'index']]\n",
        "num_nodes = accounts.shape[0]\n",
        "compact = {accounts['Account Number'][i]: accounts['index'][i] for i in range(num_nodes)}\n",
        "to_node = np.vectorize(lambda x: compact[x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "50558c81-4530-42a1-94e5-dd7b80c4c494",
      "metadata": {
        "tags": [],
        "id": "50558c81-4530-42a1-94e5-dd7b80c4c494"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.data import Data\n",
        "import torch\n",
        "\n",
        "# create adjacency list in COO format\n",
        "source = to_node(edge_data['Account'])\n",
        "target = to_node(edge_data['Account.1'])\n",
        "edge_index = torch.from_numpy(np.vstack([source, target])).to(device)\n",
        "\n",
        "num_edges = edge_index.shape[1]\n",
        "\n",
        "g = Data(edge_index=edge_index, num_nodes=num_nodes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "a8c9d5c0-bbae-4718-bdb6-35bea16cf0a4",
      "metadata": {
        "tags": [],
        "id": "a8c9d5c0-bbae-4718-bdb6-35bea16cf0a4"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.utils import degree\n",
        "import torch.nn.functional as F\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# create bank frequency column\n",
        "freq = node_data['Bank ID'].value_counts()\n",
        "id_freq = np.vectorize(lambda x: freq[x])\n",
        "node_data['Bank Frequency'] = id_freq(node_data['Bank ID'])\n",
        "node_data['Bank Frequency'] = pd.cut(node_data['Bank Frequency'], bins=[0, 2, 10, 100, 4000], labels=[0, 1, 2, 3])\n",
        "\n",
        "# use one hot encoding for categorical variables\n",
        "bank_enc = OneHotEncoder(sparse_output=False)\n",
        "bank_frequency = bank_enc.fit_transform(node_data['Bank Frequency'].to_numpy().reshape(-1, 1))\n",
        "\n",
        "paid_enc = OneHotEncoder(sparse_output=False)\n",
        "currency_sent = paid_enc.fit_transform(edge_data['Payment Currency'].to_numpy().reshape(-1, 1))\n",
        "\n",
        "received_enc = OneHotEncoder(sparse_output=False)\n",
        "currency_received = received_enc.fit_transform(edge_data['Receiving Currency'].to_numpy().reshape(-1, 1))\n",
        "\n",
        "format_enc = OneHotEncoder(sparse_output=False)\n",
        "pay_format = format_enc.fit_transform(edge_data['Payment Format'].to_numpy().reshape(-1, 1))\n",
        "\n",
        "# create numerical variables\n",
        "time_trans = pd.to_datetime(edge_data['Timestamp']).astype('int64') / 1e9\n",
        "amount_sent = edge_data['Amount Paid'].to_numpy()\n",
        "amount_received = edge_data['Amount Received'].to_numpy()\n",
        "\n",
        "# combine all edge features into one tensor with dtype = float32\n",
        "edge_features = torch.from_numpy(np.column_stack([time_trans, amount_received,\n",
        "                                                  currency_received, pay_format])).float().to(device)\n",
        "edge_dim = edge_features.shape[1]\n",
        "\n",
        "# edge label with 0 = not laundering, 1 = is laundering\n",
        "label = torch.from_numpy(edge_data['Is Laundering'].to_numpy()).long().to(device)\n",
        "\n",
        "g.x = torch.from_numpy(bank_frequency).float().to(device)\n",
        "g.edge_attr = F.normalize(edge_features)\n",
        "g.edge_label = label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "721ece0e-3927-4602-a1ff-6765ce7a88d6",
      "metadata": {
        "tags": [],
        "id": "721ece0e-3927-4602-a1ff-6765ce7a88d6"
      },
      "outputs": [],
      "source": [
        "# chronological 60/20/20 split\n",
        "\n",
        "train_end = int(0.6 * num_edges)\n",
        "val_end = int(0.8 * num_edges)\n",
        "\n",
        "train_idx = torch.zeros(num_edges, dtype=torch.bool)\n",
        "train_idx[:train_end] = True\n",
        "\n",
        "val_idx = torch.zeros(num_edges, dtype=torch.bool)\n",
        "val_idx[train_end:val_end] = True\n",
        "\n",
        "test_idx = torch.zeros(num_edges, dtype=torch.bool)\n",
        "test_idx[val_end:] = True\n",
        "\n",
        "#g.train_mask = train_idx\n",
        "#g.val_mask = val_idx\n",
        "#g.test_mask = test_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "ab993a4f-25c1-4846-a7d8-14f1741ac5bb",
      "metadata": {
        "tags": [],
        "id": "ab993a4f-25c1-4846-a7d8-14f1741ac5bb"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "\n",
        "epochs = 200\n",
        "\n",
        "pos_weight = 10\n",
        "\n",
        "embedding_dim = 64\n",
        "\n",
        "hidden = 64\n",
        "\n",
        "learn_rate = 0.005\n",
        "\n",
        "dropout = 0.4\n",
        "\n",
        "num_neighbors = [10, 5, 5, 2]\n",
        "\n",
        "batch_size = 10000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "061f4f28-349d-4507-870a-bd88445bfbbb",
      "metadata": {
        "tags": [],
        "id": "061f4f28-349d-4507-870a-bd88445bfbbb"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn import GINEConv\n",
        "import torch.nn as nn\n",
        "\n",
        "# node embedding model\n",
        "class GNN(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, embedding_dim, edge_feat_dim, dropout):\n",
        "        super().__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.hidden = hidden_channels\n",
        "        self.dim = embedding_dim\n",
        "        self.edge_dim = edge_feat_dim\n",
        "        self.drop = dropout\n",
        "\n",
        "        # linear embeddings\n",
        "        self.node_embedding = nn.Linear(self.in_channels, self.dim)\n",
        "        self.edge_embedding = nn.Linear(self.edge_dim, self.dim)\n",
        "\n",
        "        # convolution layers for node embedding\n",
        "        self.conv1 = GINEConv(nn.Sequential(\n",
        "                    nn.Linear(self.dim, self.dim),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Linear(self.dim, self.dim)\n",
        "                    ), edge_dim=self.dim)\n",
        "        self.conv2 = GINEConv(nn.Sequential(\n",
        "                    nn.Linear(self.dim, self.dim),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Linear(self.dim, self.dim)\n",
        "                    ), edge_dim=self.dim)\n",
        "\n",
        "        # mlp for edge embedding\n",
        "        self.mlp_edge = nn.Sequential(\n",
        "            nn.Linear(self.dim*3, self.dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(self.dim, self.dim),\n",
        "        )\n",
        "\n",
        "        # mlp for edge classifier\n",
        "        self.mlp_classifier = nn.Sequential(\n",
        "            nn.Linear(self.dim*3, self.hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(self.drop),\n",
        "            nn.Linear(self.hidden, self.hidden // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(self.drop),\n",
        "            nn.Linear(self.hidden // 2, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr, edge_label_index=None, edge_label_attr=None):\n",
        "        # 1. Message Passing to update node embeddings\n",
        "        x = self.node_embedding(x)\n",
        "        edge_attr_mp = self.edge_embedding(edge_attr)\n",
        "\n",
        "        # Layer 1\n",
        "        u, v = edge_index\n",
        "        x = 0.5 * (x + F.relu(self.conv1(x, edge_index, edge_attr_mp)))\n",
        "        edge_attr_mp = edge_attr_mp + 0.5*self.mlp_edge(torch.cat([x[u], x[v], edge_attr_mp], dim=-1))\n",
        "\n",
        "        # Layer 2\n",
        "        x = 0.5 * (x + F.relu(self.conv2(x, edge_index, edge_attr_mp)))\n",
        "        edge_attr_mp = edge_attr_mp + 0.5*self.mlp_edge(torch.cat([x[u], x[v], edge_attr_mp], dim=-1))\n",
        "\n",
        "        # 2. Prediction\n",
        "        if edge_label_index is not None:\n",
        "            # Use specific target edges\n",
        "            src, dst = edge_label_index\n",
        "            x_src = x[src]\n",
        "            x_dst = x[dst]\n",
        "\n",
        "            # Handle edge features for target edges\n",
        "            if edge_label_attr is not None:\n",
        "                # Re-calculate edge embedding updates for the target edges\n",
        "                # This ensures they benefit from the trained MLPs even if not in MP graph\n",
        "                h_edge = self.edge_embedding(edge_label_attr)\n",
        "\n",
        "                # Layer 1 update (simulated)\n",
        "                h_edge = h_edge + 0.5 * self.mlp_edge(torch.cat([x_src, x_dst, h_edge], dim=-1))\n",
        "                # Layer 2 update (simulated)\n",
        "                h_edge = h_edge + 0.5 * self.mlp_edge(torch.cat([x_src, x_dst, h_edge], dim=-1))\n",
        "            else:\n",
        "                # Fallback if no attributes provided (should not happen with correct loop)\n",
        "                h_edge = torch.zeros((src.size(0), self.dim), device=x.device)\n",
        "\n",
        "            # Combine for classification\n",
        "            # Original logic: x[edge_pairs].reshape(-1, 2*self.dim).relu()\n",
        "            x_pair = torch.cat([x_src, x_dst], dim=-1).relu()\n",
        "            return self.mlp_classifier(torch.cat([x_pair, h_edge], dim=1))\n",
        "\n",
        "        else:\n",
        "            # Fallback to computing for all edges in edge_index (old behavior)\n",
        "            edge_pairs = torch.transpose(edge_index, 0, 1)\n",
        "            x_pair = x[edge_pairs].reshape(-1, 2*self.dim).relu()\n",
        "            return self.mlp_classifier(torch.cat([x_pair, edge_attr_mp], dim=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "c83426b9-b278-40da-8867-be1c46ad7804",
      "metadata": {
        "tags": [],
        "id": "c83426b9-b278-40da-8867-be1c46ad7804"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, precision_recall_curve, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Helper to get edge attrs\n",
        "def get_target_edge_attrs(batch, original_idx_mask):\n",
        "    # batch.input_id gives global indices into the original graph (g)\n",
        "    # because LinkNeighborLoader was initialized with 'g'.\n",
        "    if hasattr(batch, 'input_id'):\n",
        "        return g.edge_attr[batch.input_id]\n",
        "    return None\n",
        "\n",
        "# evaluate performance\n",
        "def evaluate(loader, split_idx):\n",
        "    gnn.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    all_probs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            batch.to(device)\n",
        "            target_attr = get_target_edge_attrs(batch, split_idx)\n",
        "\n",
        "            logits = gnn(batch.x, batch.edge_index, batch.edge_attr,\n",
        "                         edge_label_index=batch.edge_label_index,\n",
        "                         edge_label_attr=target_attr)\n",
        "\n",
        "            preds = logits.argmax(dim=-1)\n",
        "\n",
        "            all_preds.append(preds.cpu())\n",
        "            all_labels.append(batch.edge_label.cpu())\n",
        "            all_probs.append(logits[:, 1].cpu())\n",
        "\n",
        "    y = torch.cat(all_labels)\n",
        "    preds = torch.cat(all_preds)\n",
        "    probs = torch.cat(all_probs)\n",
        "\n",
        "    accuracy = accuracy_score(y, preds)\n",
        "    precision = precision_score(y, preds, zero_division=0.0)\n",
        "    recall = recall_score(y, preds, zero_division=0.0)\n",
        "    f1 = f1_score(y, preds, zero_division=0.0)\n",
        "    return [accuracy, precision, recall, f1], y, preds, probs\n",
        "\n",
        "def plots(y, preds, probs):\n",
        "    cm = confusion_matrix(y, preds)\n",
        "\n",
        "    # plot confusion matrix for default threshold\n",
        "    plt.figure(1)\n",
        "    ConfusionMatrixDisplay(cm).plot()\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "    # plt.savefig('Confusion Matrix')\n",
        "\n",
        "    # plot loss curve\n",
        "    plt.figure(2)\n",
        "    plt.plot(loss_values)\n",
        "    plt.xticks(range(0,epochs))\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Validation Loss')\n",
        "    plt.show()\n",
        "    # plt.savefig('Loss Curve')\n",
        "\n",
        "    # plot precision-recall curve\n",
        "    plt.figure(3)\n",
        "    precision, recall, thresholds = precision_recall_curve(y, probs)\n",
        "    plt.plot(recall, precision, label=f'Precision-Recall Curve')\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.title('Precision-Recall Curve')\n",
        "    plt.show()\n",
        "    # plt.savefig('Precision-Recall Curve')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "230b9af0-747b-4030-b25b-6a35a9bf8324",
      "metadata": {
        "tags": [],
        "id": "230b9af0-747b-4030-b25b-6a35a9bf8324"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.loader import LinkNeighborLoader\n",
        "\n",
        "train_loader = LinkNeighborLoader(g, num_neighbors=num_neighbors,\n",
        "                                  edge_label_index=edge_index[:, train_idx],\n",
        "                                  edge_label=g.edge_label[train_idx],\n",
        "                                  batch_size=batch_size,\n",
        "                                  shuffle=True)\n",
        "\n",
        "val_loader = LinkNeighborLoader(g, num_neighbors=num_neighbors,\n",
        "                                edge_label_index=edge_index[:, val_idx],\n",
        "                                edge_label=g.edge_label[val_idx],\n",
        "                                batch_size=batch_size,\n",
        "                                shuffle=True)\n",
        "\n",
        "test_loader = LinkNeighborLoader(g, num_neighbors=num_neighbors,\n",
        "                                 edge_label_index=edge_index[:, test_idx],\n",
        "                                 edge_label=g.edge_label[test_idx],\n",
        "                                 batch_size=batch_size,\n",
        "                                 shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "25290c5e-4ab8-4061-a3fc-06d4a38be909",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "25290c5e-4ab8-4061-a3fc-06d4a38be909",
        "outputId": "59e69ad1-b5fc-4f0d-daac-dae9392fb364"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | loss 0.0581 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 02 | loss 0.0476 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 03 | loss 0.0460 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 04 | loss 0.0457 | accuracy 0.9989 | precision 0.1806| recall 0.0245| f1 0.0432\n",
            "Epoch 05 | loss 0.0444 | accuracy 0.9990 | precision 0.5000| recall 0.0066| f1 0.0130\n",
            "Epoch 06 | loss 0.0440 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 07 | loss 0.0436 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 08 | loss 0.0430 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 09 | loss 0.0428 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 10 | loss 0.0429 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 11 | loss 0.0426 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 12 | loss 0.0419 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 13 | loss 0.0424 | accuracy 0.9989 | precision 0.3485| recall 0.0434| f1 0.0771\n",
            "Epoch 14 | loss 0.0433 | accuracy 0.9989 | precision 0.3018| recall 0.0631| f1 0.1044\n",
            "Epoch 15 | loss 0.0424 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 16 | loss 0.0432 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 17 | loss 0.0423 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 18 | loss 0.0425 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 19 | loss 0.0422 | accuracy 0.9990 | precision 0.5000| recall 0.0254| f1 0.0484\n",
            "Epoch 20 | loss 0.0417 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 21 | loss 0.0429 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 22 | loss 0.0418 | accuracy 0.9990 | precision 0.5161| recall 0.0151| f1 0.0293\n",
            "Epoch 23 | loss 0.0423 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 24 | loss 0.0417 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 25 | loss 0.0418 | accuracy 0.9989 | precision 0.2286| recall 0.0151| f1 0.0283\n",
            "Epoch 26 | loss 0.0421 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 27 | loss 0.0475 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 28 | loss 0.0492 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 29 | loss 0.0453 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 30 | loss 0.0447 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 31 | loss 0.0446 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 32 | loss 0.0441 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 33 | loss 0.0447 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 34 | loss 0.0445 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 35 | loss 0.0433 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 36 | loss 0.0435 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 37 | loss 0.0435 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 38 | loss 0.0430 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 39 | loss 0.0430 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 40 | loss 0.0429 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 41 | loss 0.0432 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 42 | loss 0.0444 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 43 | loss 0.0438 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 44 | loss 0.0426 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 45 | loss 0.0427 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 46 | loss 0.0431 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 47 | loss 0.0419 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 48 | loss 0.0430 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 49 | loss 0.0430 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 50 | loss 0.0422 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 51 | loss 0.0433 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 52 | loss 0.0457 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 53 | loss 0.0450 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 54 | loss 0.0460 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 55 | loss 0.0523 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 56 | loss 0.0508 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 57 | loss 0.0499 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 58 | loss 0.0496 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 59 | loss 0.0506 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 60 | loss 0.0505 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 61 | loss 0.0504 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 62 | loss 0.0511 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 63 | loss 0.0522 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 64 | loss 0.0522 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 65 | loss 0.0521 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 66 | loss 0.0521 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 67 | loss 0.0522 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 68 | loss 0.0521 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 69 | loss 0.0523 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 70 | loss 0.0523 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 71 | loss 0.0523 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 72 | loss 0.0523 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n",
            "Epoch 73 | loss 0.0549 | accuracy 0.9990 | precision 0.0000| recall 0.0000| f1 0.0000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2646158205.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mbatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mgnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/loader/base.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/loader/link_loader.py\u001b[0m in \u001b[0;36mcollate_fn\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0minput_data\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mEdgeSamplerInput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         out = self.link_sampler.sample_from_edges(\n\u001b[0m\u001b[1;32m    212\u001b[0m             input_data, neg_sampling=self.neg_sampling)\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/sampler/neighbor_sampler.py\u001b[0m in \u001b[0;36msample_from_edges\u001b[0;34m(self, inputs, neg_sampling)\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0mneg_sampling\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mNegativeSampling\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     ) -> Union[SamplerOutput, HeteroSamplerOutput]:\n\u001b[0;32m--> 334\u001b[0;31m         out = edge_sample(inputs, self._sample, self.num_nodes, self.disjoint,\n\u001b[0m\u001b[1;32m    335\u001b[0m                           self.node_time, neg_sampling)\n\u001b[1;32m    336\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubgraph_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSubgraphType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbidirectional\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/sampler/neighbor_sampler.py\u001b[0m in \u001b[0;36medge_sample\u001b[0;34m(inputs, sample_fn, num_nodes, disjoint, node_time, neg_sampling)\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0mseed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msrc_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst_time\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0;31m# Enhance `out` by label information ##################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/sampler/neighbor_sampler.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, seed, seed_time, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m                 )\n\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbor_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m                 \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;31m# We save the function ptr as the `op` attribute on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m         \u001b[0;31m# OpOverloadPacket to access it here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[0;31m# TODO: use this to make a __dir__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# instantiate model\n",
        "gnn = GNN(4, hidden, embedding_dim, edge_dim, dropout).to(device)\n",
        "weight = torch.tensor([1, pos_weight]).float().to(device)\n",
        "optimizer = optim.Adam(gnn.parameters(), lr=learn_rate)\n",
        "criterion = nn.CrossEntropyLoss(weight=weight).to(device)\n",
        "\n",
        "# training loop\n",
        "loss_values = []\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    batches = 0\n",
        "    for batch in train_loader:\n",
        "        batch.to(device)\n",
        "        gnn.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Fetch raw edge attributes for the target edges\n",
        "        target_attr = get_target_edge_attrs(batch, train_idx)\n",
        "\n",
        "        # Compute logits ONLY for the target edges using edge_label_index\n",
        "        logits = gnn(batch.x, batch.edge_index, batch.edge_attr,\n",
        "                     edge_label_index=batch.edge_label_index,\n",
        "                     edge_label_attr=target_attr)\n",
        "\n",
        "        loss = criterion(logits, batch.edge_label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        batches += 1\n",
        "\n",
        "    avg_loss = total_loss / batches\n",
        "    loss_values.append(avg_loss)\n",
        "\n",
        "    # Use the updated evaluate function\n",
        "    val_metrics, _, _, _ = evaluate(val_loader, val_idx)\n",
        "    print(f'Epoch {epoch+1:02d} | loss {avg_loss:.4f} | accuracy {val_metrics[0]:.4f} | precision {val_metrics[1]:.4f}| recall {val_metrics[2]:.4f}| f1 {val_metrics[3]:.4f}')\n",
        "\n",
        "# evaluate metrics on test data\n",
        "test_metrics, y_test, preds_test, probs_test = evaluate(test_loader, test_idx)\n",
        "print('\\n')\n",
        "print(f'Test Accuracy: {test_metrics[0]:.4f}')\n",
        "print(f'Test Precision: {test_metrics[1]:.4f}')\n",
        "print(f'Test Recall: {test_metrics[2]:.4f}')\n",
        "print(f'Test f1: {test_metrics[3]:.4f}')\n",
        "\n",
        "plots(y_test, preds_test, probs_test)\n",
        "torch.save(gnn, 'model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(gnn, 'model.pth')"
      ],
      "metadata": {
        "id": "uWjqH_UkQ9U3"
      },
      "id": "uWjqH_UkQ9U3",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}